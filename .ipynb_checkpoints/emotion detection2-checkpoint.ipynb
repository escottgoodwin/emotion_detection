{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from stop_words import get_stop_words\n",
    "from gensim.models.doc2vec import TaggedDocument,Doc2Vec\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial,stats\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text Data</h2>\n",
    "\n",
    "Reads in the ISEAR emotion dataset into Pandas dataframe. http://emotion-research.net/toolbox/toolboxdatabase.2006-10-13.2581092615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isear = pd.read_csv('ISEAR1.csv',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                               text\n",
       "0      joy  On days when I feel close to my partner and ot...\n",
       "1     fear  Every time I imagine that someone I love or I ...\n",
       "2    anger  When I had been obviously unjustly treated and...\n",
       "3  sadness  When I think about the short time that we live...\n",
       "4  disgust  At a gathering I found myself involuntarily si..."
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_isear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preparation and Doc2Vec Model Creation</h2>\n",
    "\n",
    "Define functions to process text and create a doc2vec model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First function takes a collection of articles or strings items and creates a doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doc2vec_model(articles,name,vector_size=100,epochs=10,lang='en'):\n",
    "    # import stopwords for specific language of model\n",
    "    stop_words = get_stop_words(lang)\n",
    "    ## list of just articles (str)\n",
    "    #strip stopwords article docs\n",
    "    nostop = [[i for i in doc.lower().split() if i not in stop_words] for doc in articles]\n",
    "    #tokenize article docs and convert to doc2vec tagged docs - each article has an index number and list of tokens - taggedoc(['token1','token2',[1]])\n",
    "    tagged = [TaggedDocument(doc,[i]) for i,doc in enumerate(nostop)]\n",
    "    # instantiate doc2vec model with parameters - size = # of nums representing each doc (100), min_count - occurences of words in vocab (filter out rare words), iter - passes to create vectors\n",
    "    model = Doc2Vec(vector_size=vector_size, min_count=2, epochs=epochs)\n",
    "    ## build vocab from all tagged docs\n",
    "    model.build_vocab(tagged)\n",
    "    ## train model on tagged docs - total examples - total # of docs\n",
    "    model.train(tagged,total_examples=model.corpus_count,epochs=epochs)\n",
    "    # save model with language - eg esmodel.model for spanish docs\n",
    "    model_name = name + 'model.model'\n",
    "    model.save(model_name)\n",
    "    model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "    print('saved as: ' + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts a list of articles (strings) and infers the vector from the doc2vec model previously created. \n",
    "Input ['string1','string2','string3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(textlist,lang,d2v_model):\n",
    "    stop_words = get_stop_words(lang)\n",
    "    histnostop = [[i for i in doc.lower().split() if i not in stop_words] for doc in textlist]\n",
    "    dlhist_tagged = [TaggedDocument(doc,[i]) for i,doc in enumerate(histnostop)]\n",
    "    ## infer vectors from current doc2model\n",
    "    vecs = [d2v_model.infer_vector(doc.words) for doc in dlhist_tagged]\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creates and Loads Doc2Vec Model</h2>\n",
    "\n",
    "Creates a doc2vec model from just the text of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_text = df_isear['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: emotions1model.model\n"
     ]
    }
   ],
   "source": [
    "create_doc2vec_model(emot_text,'emotions1',vector_size=100,epochs=10,lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = Doc2Vec.load('emotions1model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text Item Vectors</h2>\n",
    "\n",
    "Gets the vectors for each text item in the dataframe from the doc2vec just created and add them to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7516"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emot_vecs = [d2v_model.docvecs[x] for x in range(len(emot_text))]\n",
    "len(emot_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isear['emot_vecs'] = emot_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Group Vectors by Emotion</h2>\n",
    "\n",
    "Group Dataframe by emotion(anger,joy,sadness etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_grp = list(df_isear.groupby(df_isear['emotion']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Calculate Vector Mean for Each Emotion Group</h2>\n",
    "\n",
    "Get vector means (centers) for each emotion group. This represents the central location in the vector space for each emotion. The closer a text vector representation is to a given emotion group mean, the more the given text is characterized by the emotion the mean represents. \n",
    "\n",
    "Example: the closer a given sentence is to the 'anger' vector center, the more that sentence is characterized by anger. I purposely use the word 'characterize' because the model can capture a wide variation of relations to the emotion - expressions, descriptions, evaluations, etc. \n",
    "\n",
    "A characterization of an emotion contains all 3 of the following cases:\n",
    "\n",
    "An expression of anger - \"I hate that no good bastard and I want to bash his head in.' \n",
    "A description of anger - \"When she told him she cheated, he banged his fist against the wall and gritted his teeth'\n",
    "A evaluation of someone else's anger - \"I was so disappointed when cursed and stormed out of the room when given the news.' \n",
    "\n",
    "Another viewpoint sees the emotion 'score' as the amount of emotion 'content' in the sentence, without necessarily being an expression of that emotion. The third sentence, for instance, is an expression of disappointment, though it has high anger 'content.' A sentence with a high anger 'score,' therefore, doesn't mean the sentence itself is particularly angry. \n",
    "\n",
    "We can then evaluate a sentence for it's emotional 'content' by calculating the distance of the sentence vector from each of the emotion vector means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_vec_mean = [{'emotion':emotions_grp[x][0],'vec':emotions_grp[x][1]['emot_vecs'].mean()} for x in range(len(emotions_grp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_vec_mean1 = [emot_vec_mean[x]['vec'] for x in range(len(emot_vec_mean))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_vecs_ctr = [x['vec'] for x in emot_vec_mean]\n",
    "emot_label_ctr = [x['emotion'] for x in emot_vec_mean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create .tsv files</h2>\n",
    "\n",
    "Functions for creating tsv files for use in a Tensorflow Embedding Projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## outputs and saves a tsv file for a list of vectors\n",
    "def output_tab_vecs(vecs,filename):\n",
    "    csv.register_dialect('tabDialect', delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    myFile = open(filename, 'w')  \n",
    "    with myFile:  \n",
    "        writer = csv.writer(myFile, dialect='tabDialect')\n",
    "        writer.writerows(vecs)\n",
    "    print('saved tab file as',filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## outputs and saves a tsv file for a list of meta tags (2 columns or more)\n",
    "def output_tab_meta(meta,filename):\n",
    "    csv.register_dialect('tabDialect', delimiter='\\t', quoting=csv.QUOTE_NONE,escapechar='\\\\')\n",
    "    myFile = open(filename, 'w')  \n",
    "    with myFile:  \n",
    "        writer = csv.writer(myFile, dialect='tabDialect')\n",
    "        writer.writerows(meta)\n",
    "    print('saved tab file as',filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## outputs and saves a tsv file for a list of single column meta tags\n",
    "def output_single_meta(metalist,filename):\n",
    "    with open (filename, 'w') as fo:\n",
    "        for d in metalist:\n",
    "            fo.write(str(d) + '\\n')\n",
    "    print('saved tab file as',filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output tsv files for the vector means for each emotion and theirs labels as well as the vectors for each sentence and their labels (emotion,sentence text). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tab file as emot_vecs_means.tsv\n"
     ]
    }
   ],
   "source": [
    "output_tab_vecs(emot_vecs_ctr,'emot_vecs_means.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tab file as emot_labels_means.tsv\n"
     ]
    }
   ],
   "source": [
    "output_single_meta(emot_label_ctr,'emot_labels_means.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tab file as emot_vecs_sent.tsv\n"
     ]
    }
   ],
   "source": [
    "output_tab_vecs(emot_vecs,'emot_vecs_sent.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tab file as emot_labels_sent.tsv\n"
     ]
    }
   ],
   "source": [
    "meta_list = list(zip(df_isear['emotion'],df_isear['text']))\n",
    "output_tab_meta(meta_list,'emot_labels_sent.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tensorflow Embedding Projector </h2>\n",
    "\n",
    "Links use data previously generated in this notebook that is hosted on github. To use yoru own data, one can generate the required tsv files with the functions above and then upload the vec and meta .tsv files to the embedding projector with the 'Load Data' button and choose the appropriate file (vectors or metadata). \n",
    "\n",
    "<h3>All Sentences</h3>\n",
    "\n",
    "Select 'emotion' for 'color by' so points will be colored by the emotion label.\n",
    "\n",
    "https://projector.tensorflow.org/?config=https://gist.githubusercontent.com/escottgoodwin/f3728570bf3c7e13a750dd93117053ac/raw/cdeb31000cf4235f297e7315faf35b9a8b398ece/emot_vec2_projector_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Emotion Vector Means</h3>\n",
    "\n",
    "Select 'emotion' for 'color by' so points will be colored by the emotion label.\n",
    "\n",
    "https://projector.tensorflow.org/?config=https://gist.githubusercontent.com/escottgoodwin/1a8e0715f2c6029e835f4a6e315bdd92/raw/904d094e39c443bcae221a247e023c7a30620337/emotion_centers_projector_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Emotional Content Predictions</h2>\n",
    "\n",
    "Predicts the emotional content of a list of text articles (strings) \n",
    "\n",
    "<b>Outputs:</b>\n",
    "\n",
    "1 - score for each of the 7 emotions based on cosine distance from emotion vector means - anger:84,joy:21,sadness: .65\n",
    "\n",
    "2 - dominant emotion (to compare to original ISEAR dataset that had 1 emotion per sentence) - anger\n",
    "\n",
    "3 - ranks of the each of the 7 emotions - in reverse order by distance - most dominant emotion would be 7 - joy:1,sadness:5, anger:7 \n",
    "\n",
    "4 - inferred vectors each item in the list of text articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotions(text_list,lang,emot_vec_mean,model_name):\n",
    "    d2v_model = Doc2Vec.load(model_name)\n",
    "    text_vecs = text2vec(text_list,lang,d2v_model)\n",
    "    emot_scan = [{x['emotion']:1 - spatial.distance.cosine(sample_vec,x['vec']) for x in emot_vec_mean} for sample_vec in text_vecs]\n",
    "    emot_scan1 = [[1 - spatial.distance.cosine(sample_vec,x['vec']) for x in emot_vec_mean] for sample_vec in text_vecs]\n",
    "    emot_pred = [np.argmax(x) for x in emot_scan1]\n",
    "    ranks = [stats.rankdata(x) for x in emot_scan1]\n",
    "    emotions = [x['emotion'] for x in  emot_vec_mean]\n",
    "    emot_ranks = []\n",
    "    for x in range(len(ranks)):\n",
    "        emot_rank = list(zip(emotions,ranks[x]))\n",
    "        emot_ranks.append(emot_rank)\n",
    "    return emot_scan,emot_scan1,emot_pred,emot_ranks,text_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sent = ['You mean so much to me and I love you.','How could you do that you bastard. I cannot stand you!'] #sentences must be in a list\n",
    "emot_scan,emot_scan1,emot_pred,ranks,text_vecs = predict_emotions(sample_sent,'en',emot_vec_mean,'emotions1model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'anger': 0.9852735996246338,\n",
       "  'disgust': 0.985318660736084,\n",
       "  'fear': 0.9851565361022949,\n",
       "  'guilt': 0.9853554964065552,\n",
       "  'joy': 0.9850506782531738,\n",
       "  'sadness': 0.9850685000419617,\n",
       "  'shame': 0.9853231906890869},\n",
       " {'anger': 0.9795728921890259,\n",
       "  'disgust': 0.9795154929161072,\n",
       "  'fear': 0.9794973134994507,\n",
       "  'guilt': 0.9795477986335754,\n",
       "  'joy': 0.9796198010444641,\n",
       "  'sadness': 0.9794784188270569,\n",
       "  'shame': 0.9796500205993652}]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emot_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('anger', 4.0),\n",
       "  ('disgust', 5.0),\n",
       "  ('fear', 3.0),\n",
       "  ('guilt', 7.0),\n",
       "  ('joy', 1.0),\n",
       "  ('sadness', 2.0),\n",
       "  ('shame', 6.0)],\n",
       " [('anger', 5.0),\n",
       "  ('disgust', 3.0),\n",
       "  ('fear', 2.0),\n",
       "  ('guilt', 4.0),\n",
       "  ('joy', 6.0),\n",
       "  ('sadness', 1.0),\n",
       "  ('shame', 7.0)]]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Emotions Related By Distance</h2>\n",
    "\n",
    "One nice feature of modeling the emotional content of the text in the vector space this way is that it takes into account that certain emotions are related (or near in vector space) to one another. This is an improvement upon an LDA style model that would simply give proportions percentages of emotional content that add to %100 - anger:25%, joy: 5%. \n",
    "\n",
    "Of course, one could transform the scores into percentages, but the accuracy of the characterization might be lost. \n",
    "\n",
    "In this model, the vector means for disgust and anger are near one another, so one would expect that a text that 'scored' high for anger, would also 'score' high for disgust. \n",
    "\n",
    "How accurate the relations (or distances) depicted by the model are another matter. Anger and disgust being so close makes a cetain amount of sense. However, joy and sadness between so close together and shame and guilt being so far apart make less sense. Now is this fault of the modeling method or a peculiarity of the dataset?  \n",
    "\n",
    "<center><h4>Emotion Vector Centers</h4></center>\n",
    "\n",
    "<img src=\"screenshotemotvec.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Emotion Cluster Separation</h2>\n",
    "\n",
    "The following functions explores how well the various emotion vector means are seperated by looking at the cosine distances between the vector means and the text vectors in each of the emotion groups. \n",
    "\n",
    "We calculate the distances between the vector mean for anger and all the text vectors in the anger group. We do the same for the anger vector mean and the all the articles in the six other groups (anger mean and disgust text vectors, anger mean and sadness text vectors etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_ctr_dist(emot,ctr):\n",
    "    emot_ser = df_isear[df_isear['emotion']==emot]['emot_vecs']\n",
    "    emot_dist = np.array([spatial.distance.cosine(ctr,x) for x in emot_ser])\n",
    "    print(emot)\n",
    "    print(stats.describe(emot_dist))\n",
    "    plt.hist(emot_dist)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctr_dist_compare(emot_list,ctr_list):\n",
    "    for emotion in emot_list:\n",
    "        print('main emotion',emotion)\n",
    "        for ctr in emot_vec_mean:\n",
    "            print(ctr['emotion'])\n",
    "            emotion_ctr_dist(emotion,ctr['vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr_dist_compare(emot_lablel_ctr,emot_vecs_ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
