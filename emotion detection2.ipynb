{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from stop_words import get_stop_words\n",
    "from gensim.models.doc2vec import TaggedDocument,Doc2Vec\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial,stats\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doc2vec_model(articles,name,vector_size=100,epochs=10,lang='en'):\n",
    "    # import stopwords for specific language of model\n",
    "    stop_words = get_stop_words(lang)\n",
    "    ## list of just articles (str)\n",
    "    #strip stopwords article docs\n",
    "    nostop = [[i for i in doc.lower().split() if i not in stop_words] for doc in articles]\n",
    "    #tokenize article docs and convert to doc2vec tagged docs - each article has an index number and list of tokens - taggedoc(['token1','token2',[1]])\n",
    "    tagged = [TaggedDocument(doc,[i]) for i,doc in enumerate(nostop)]\n",
    "    # instantiate doc2vec model with parameters - size = # of nums representing each doc (100), min_count - occurences of words in vocab (filter out rare words), iter - passes to create vectors\n",
    "    model = Doc2Vec(vector_size=vector_size, min_count=2, epochs=epochs)\n",
    "    ## build vocab from all tagged docs\n",
    "    model.build_vocab(tagged)\n",
    "    ## train model on tagged docs - total examples - total # of docs\n",
    "    model.train(tagged,total_examples=model.corpus_count,epochs=epochs)\n",
    "    # save model with language - eg esmodel.model for spanish docs\n",
    "    model_name = name + 'model.model'\n",
    "    model.save(model_name)\n",
    "    model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "    print('saved as: ' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(textlist,lang,d2v_model):\n",
    "    stop_words = get_stop_words(lang)\n",
    "    histnostop = [[i for i in doc.lower().split() if i not in stop_words] for doc in textlist]\n",
    "    dlhist_tagged = [TaggedDocument(doc,[i]) for i,doc in enumerate(histnostop)]\n",
    "    ## infer vectors from current doc2model\n",
    "    vecs = [d2v_model.infer_vector(doc.words) for doc in dlhist_tagged]\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotions(text_list,lang,emotion_vecs,model_name):\n",
    "    d2v_model = Doc2Vec.load(model_name)\n",
    "    text_vecs = text2vec(text_list,lang,d2v_model)\n",
    "    emot_scan = [[1 - spatial.distance.cosine(sample_vec,x) for x in emot_vecs]for sample_vec in text_vecs]\n",
    "    emot_pred = [np.argmax(x) for x in emot_scan]\n",
    "    return emot_scan,emot_pred,text_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isear = pd.read_csv('ISEAR.csv',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_id = []\n",
    "for x in df_isear['emotion']:\n",
    "    if x == 'anger':\n",
    "        emotion_id.append(0)\n",
    "    if x == 'disgust':\n",
    "        emotion_id.append(1)\n",
    "    if x == 'fear':\n",
    "        emotion_id.append(2)\n",
    "    if x == 'guilt':\n",
    "        emotion_id.append(3)\n",
    "    if x == 'joy':\n",
    "        emotion_id.append(4)\n",
    "    if x == 'sadness':\n",
    "        emotion_id.append(5)\n",
    "    if x == 'shame':\n",
    "        emotion_id.append(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isear['id'] = emotion_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                               text  id\n",
       "0      joy  On days when I feel close to my partner and ot...   4\n",
       "1     fear  Every time I imagine that someone I love or I ...   2\n",
       "2    anger  When I had been obviously unjustly treated and...   0\n",
       "3  sadness  When I think about the short time that we live...   5\n",
       "4  disgust  At a gathering I found myself involuntarily si...   1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_isear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_text = df_isear['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as: emotions1model.model\n"
     ]
    }
   ],
   "source": [
    "create_doc2vec_model(emot_text ,'emotions1',vector_size=100,epochs=10,lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = Doc2Vec.load('emotions1model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_vecs = [d2v_model.docvecs[x] for x in range(len(emot_text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7516"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emot_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isear['emot_vecs'].to_csv('output.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isear['emot_vecs'] = emot_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_grp = list(df_isear.groupby(df_isear['emotion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emotions_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_vec_mean = [{'emotion':emotions_grp[x][0],'vec':emotions_grp[x][1]['emot_vecs'].mean()} for x in range(len(emotions_grp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-3080887f0ceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memot_vec_mean1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0memot_vec_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memot_vec_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-77-3080887f0ceb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memot_vec_mean1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0memot_vec_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memot_vec_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "emot_vec_mean1 = [emot_vec_mean[x]['vec'] for x in range(len(emot_vec_mean))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_vecs_ctr = [x['vec'] for x in emot_vec_mean]\n",
    "emot_lablel_ctr = [x['emotion'] for x in emot_vec_mean]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_tab_vecs(vecs,filename):\n",
    "    csv.register_dialect('tabDialect', delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    myFile = open(filename, 'w')  \n",
    "    with myFile:  \n",
    "        writer = csv.writer(myFile, dialect='tabDialect')\n",
    "        writer.writerows(vecs)\n",
    "    print('saved tab file as',filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_tab_meta(meta,filename):\n",
    "    csv.register_dialect('tabDialect', delimiter='\\t', quoting=csv.QUOTE_NONE,escapechar='\\\\')\n",
    "    myFile = open(filename, 'w')  \n",
    "    with myFile:  \n",
    "        writer = csv.writer(myFile, dialect='tabDialect')\n",
    "        writer.writerows(meta)\n",
    "    print('saved tab file as',filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_tab_meta(meta,filename):\n",
    "    csv.register_dialect('tabDialect', delimiter='\\t', quoting=csv.QUOTE_NONE,escapechar='\\\\')\n",
    "    myFile = open(filename, 'w')  \n",
    "    with myFile:  \n",
    "        writer = csv.writer(myFile, dialect='tabDialect')\n",
    "        writer.writerows(meta)\n",
    "    print('saved tab file as',filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tab file as emot_vecs_ctr.tsv\n"
     ]
    }
   ],
   "source": [
    "output_tab_vecs(emot_vecs_ctr,'emot_vecs_ctr.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'disgust', 'fear', 'guilt', 'joy', 'sadness', 'shame']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_single_meta(metalist,filename):\n",
    "    with open (filename, 'w') as fo:\n",
    "        for d in metalist:\n",
    "            fo.write(str(d) + '\\n')\n",
    "    print('saved tab file as',filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tab file as emot_lablel_ctr.tsv\n"
     ]
    }
   ],
   "source": [
    "output_single_meta(emot_lablel_ctr,'emot_lablel_ctr.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotions(text_list,lang,emot_vec_mean,model_name):\n",
    "    d2v_model = Doc2Vec.load(model_name)\n",
    "    text_vecs = text2vec(text_list,lang,d2v_model)\n",
    "    emot_scan = [{x['emotion']:1 - spatial.distance.cosine(sample_vec,x['vec']) for x in emot_vec_mean} for sample_vec in text_vecs]\n",
    "    emot_scan1 = [[1 - spatial.distance.cosine(sample_vec,x['vec']) for x in emot_vec_mean] for sample_vec in text_vecs]\n",
    "    emot_pred = [np.argmax(x) for x in emot_scan1]\n",
    "    ranks = [stats.rankdata(x) for x in emot_scan1]\n",
    "    return emot_scan,emot_scan1,emot_pred,ranks,text_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sent = ['I hate you. You make me so upset.','I love you man. You make me so happy.','I am so unhappy and I cannot go on.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_scan,emot_scan1,emot_pred,ranks,text_vecs = predict_emotions(sample_sent,'en',emot_vec_mean,'emotions1model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.73958484e-02, -4.73076291e-02,  2.44500283e-02,  1.18435808e-02,\n",
       "        5.73316915e-03, -9.49813332e-03, -1.14797102e-02,  1.42994467e-02,\n",
       "        2.32999083e-02,  2.07103174e-02,  4.00470616e-03, -1.66813973e-02,\n",
       "       -3.19475010e-02, -1.60261635e-02, -8.92755948e-03, -3.88043337e-02,\n",
       "        7.72011513e-03,  4.28962894e-03, -3.63979265e-02,  9.55944136e-03,\n",
       "        2.72409450e-02, -1.91568006e-02, -4.82461974e-02,  2.43208394e-03,\n",
       "        5.93350502e-03, -4.11963426e-02, -2.72584595e-02,  7.64230965e-03,\n",
       "       -1.34155359e-02,  1.88325197e-02, -2.51454189e-02,  4.58628759e-02,\n",
       "       -9.59073193e-03,  3.14019360e-02, -4.01573442e-02, -1.92378424e-02,\n",
       "       -2.12946255e-02,  7.19871977e-03, -6.12819521e-03, -4.49165329e-03,\n",
       "       -9.75790899e-03,  1.26261115e-02,  4.73949611e-02, -1.71859004e-02,\n",
       "        1.86703242e-02, -2.43627802e-02, -1.54108563e-02, -1.48116974e-02,\n",
       "       -9.29673624e-05, -4.66659851e-03, -3.38539295e-02,  3.07363719e-02,\n",
       "        7.83427339e-03, -1.88983995e-02, -1.17212590e-02,  1.16057033e-02,\n",
       "        1.43308192e-03, -6.13412168e-03, -3.40681188e-02, -2.39694901e-02,\n",
       "        1.91031210e-02, -2.59879306e-02,  4.12504422e-03, -1.26810987e-02,\n",
       "        1.66033134e-02, -4.52391729e-02, -2.34934390e-02, -3.34251076e-02,\n",
       "        1.51609182e-02, -1.17527489e-02, -2.25312449e-03, -3.28996591e-02,\n",
       "       -2.87125609e-03, -1.48539068e-02,  5.38873253e-03, -2.74703465e-02,\n",
       "       -3.27388942e-02,  1.82132628e-02, -4.83547524e-03, -1.90546259e-03,\n",
       "        3.42552438e-02,  3.63751575e-02,  2.03566011e-02,  2.60042176e-02,\n",
       "        3.76586951e-02, -3.59500572e-03,  4.50571664e-02, -2.90986467e-02,\n",
       "       -5.57896346e-02,  1.10760443e-02, -3.46161164e-02,  2.40396634e-02,\n",
       "        4.06594761e-03,  2.07170844e-03, -1.81524493e-02,  2.79137567e-02,\n",
       "       -1.78037677e-02, -2.53586448e-03,  3.57920267e-02,  2.37389444e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_tab_vecs(vecs,filename):\n",
    "    csv.register_dialect('tabDialect', delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    myFile = open(filename, 'w')  \n",
    "    with myFile:  \n",
    "        writer = csv.writer(myFile, dialect='tabDialect')\n",
    "        writer.writerows(vecs)\n",
    "    print('saved tab file as',filename)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tab file as emot_ctr_vecs.tsv\n"
     ]
    }
   ],
   "source": [
    "output_tab_vecs(text_vecs,'emot_ctr_vecs.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.26289281,  0.3773383 ,  0.29294954,  0.92111834, -1.59419402,\n",
       "        -1.3346986 ,  0.07459363]),\n",
       " array([ 1.9272342 ,  0.03010905, -1.64427464, -0.08967182,  0.40652682,\n",
       "        -0.63862501,  0.00870141]),\n",
       " array([-1.58932613, -0.87037189, -0.35642639,  1.75559065,  0.41378003,\n",
       "         0.57536677,  0.07138697])]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[preprocessing.scale(x) for x in emot_scan1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.993009090423584, 0.9930384159088135, 0.9931976795196533, 0.9932223558425903, 0.9932318925857544, 0.9932933449745178, 0.9933319687843323]\n",
      "[0.9309930205345154, 0.9312282204627991, 0.9313566088676453, 0.9313796162605286, 0.9313846230506897, 0.931472659111023, 0.9318283200263977]\n",
      "[0.9858265519142151, 0.9858867526054382, 0.9859297871589661, 0.9859656095504761, 0.985994279384613, 0.986007809638977, 0.9861066341400146]\n"
     ]
    }
   ],
   "source": [
    "for x in emot_scan:\n",
    "    print(sorted(x.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_emot = []\n",
    "for x in emot_scan:\n",
    "    item = []\n",
    "    for w in sorted(x, key=x.get, reverse=True):\n",
    "        item.append([w, x[w]])\n",
    "    sort_emot.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['anger', 0.9933319687843323],\n",
       "  ['guilt', 0.9932933449745178],\n",
       "  ['disgust', 0.9932318925857544],\n",
       "  ['fear', 0.9932223558425903],\n",
       "  ['shame', 0.9931976795196533],\n",
       "  ['sadness', 0.9930384159088135],\n",
       "  ['joy', 0.993009090423584]],\n",
       " [['anger', 0.9318283200263977],\n",
       "  ['joy', 0.931472659111023],\n",
       "  ['disgust', 0.9313846230506897],\n",
       "  ['shame', 0.9313796162605286],\n",
       "  ['guilt', 0.9313566088676453],\n",
       "  ['sadness', 0.9312282204627991],\n",
       "  ['fear', 0.9309930205345154]],\n",
       " [['guilt', 0.9861066341400146],\n",
       "  ['sadness', 0.986007809638977],\n",
       "  ['joy', 0.985994279384613],\n",
       "  ['shame', 0.9859656095504761],\n",
       "  ['fear', 0.9859297871589661],\n",
       "  ['disgust', 0.9858867526054382],\n",
       "  ['anger', 0.9858265519142151]]]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(emot_scan[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
